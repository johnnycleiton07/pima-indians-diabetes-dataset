###### PT

# Aplica√ß√£o de algoritmos de ML e an√°lise explorat√≥ria no Pima Indians Diabetes Dataset

JOHNNY CLEITON  |  JOSS TIMOTEO  |  RAPHAEL FEITOSA

Este trabalho, desenvolvido no contexto da p√≥s-gradua√ß√£o em *Ci√™ncia de Dados e Analytics*, investiga o uso do *Pima Indians Diabetes Dataset* como base para estudo aplicado em sa√∫de. A pesquisa contempla mapeamento de stakeholders, invent√°rio de dados e revis√£o de trabalhos relacionados, al√©m de pr√°ticas fundamentais como pr√©-processamento, an√°lise explorat√≥ria e visualiza√ß√£o de dados. Por fim, s√£o aplicados algoritmos de *machine learning*, com destaque para *K-Means* e *√Årvore de Decis√£o*, visando a extra√ß√£o de padr√µes relevantes e a gera√ß√£o de *insights* que possam contribuir para a compreens√£o do diabetes.

## BACKGROUND

O *Pima Indians Diabetes Dataset* √© um conjunto de dados p√∫blico amplamente utilizado em aprendizado de m√°quina para problemas de classifica√ß√£o bin√°ria (diab√©ticos vs n√£o-diab√©ticos). Ele cont√©m informa√ß√µes de 768 mulheres Pima √≠ndias, povo ind√≠gena do sudoeste dos EUA, com 21 anos ou mais. Esse grupo tem sido foco de diversos estudos m√©dicos devido √† alta preval√™ncia de obesidade e diabetes tipo 2 (n√£o insulino-dependente) entre seus membros.



### Mapeamento de Stakeholders

No contexto do *Pima Indians Diabetes Dataset* e de um trabalho em Ci√™ncia de Dados, o mapeamento de *stakeholders* identifica as partes interessadas ou impactadas pelo estudo, ou seja, os ‚Äúatores‚Äù mais relevantes para o projeto, como pacientes, profissionais de sa√∫de e pesquisadores, entre outros.

<div align="center">
  
| ![Matriz de Influ√™ncia e Interesse](/assets/matriz-influencia-interesse.png) |
|:--:|
| *Matriz de Influ√™ncia e Interesse* |

</div>

### Invent√°rio de Dados

Esse levantamento permite organizar e documentar todas as fontes de dados dispon√≠veis, incluindo o *Pima Indians Diabetes Dataset*, estat√≠sticas de sa√∫de p√∫blica, registros populacionais e estudos acad√™micos relacionados ao diabetes.

- [Diabetes Health Indicators Dataset - BRFSS](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators)
- [Diabetes around the world in 2024 - IDF](https://idf.org/about-diabetes/diabetes-facts-figures/)


### Trabalhos Relacionados

A an√°lise de trabalhos relacionados permite contextualizar o estudo dentro da literatura existente, identificando abordagens, metodologias e resultados j√° aplicados ao *Pima Indians Diabetes Dataset* e a outros conjuntos de dados sobre diabetes.

- [Building Risk Prediction Models for Type 2 Diabetes Using Machine Learning Techniques](https://pubmed.ncbi.nlm.nih.gov/31538566/)
- [A Comparative Study of Diabetes Detection Using The Pima Indian Diabetes Database](https://www.researchgate.net/publication/374730950_A_COMPARATIVE_STUDY_OF_DIABETES_DETECTION_USING_THE_PIMA_INDIAN_DIABETES_DATABASE)


## PREPARA√á√ÉO

### Dicion√°rio de Dados

<div align="center">

| **Vari√°vel**             | **Descri√ß√£o**                                         | **Tipo de Dado**       | **Valores Poss√≠veis**       |
|---------------------------|-------------------------------------------------------|------------------------|-----------------------------|
| Pregnancies               | N√∫mero de vezes que a paciente esteve gr√°vida         | Inteiro                | ‚â• 0                         |
| Glucose                   | Concentra√ß√£o de glicose no plasma (teste de toler√¢ncia) | Num√©rico (cont√≠nuo)    | ‚â• 0 (0 = ausente)           |
| BloodPressure             | Press√£o arterial diast√≥lica                           | Num√©rico (cont√≠nuo)    | ‚â• 0 (0 = ausente)           |
| SkinThickness             | Espessura da dobra cut√¢nea do tr√≠ceps                 | Num√©rico (cont√≠nuo)    | ‚â• 0 (0 = ausente)           |
| Insulin                   | N√≠vel de insulina s√©rica em 2 horas                   | Num√©rico (cont√≠nuo)    | ‚â• 0 (0 = ausente)           |
| BMI                       | √çndice de Massa Corporal (peso/altura¬≤)               | Num√©rico (decimal)     | ‚â• 0 (0 = ausente)           |
| DiabetesPedigreeFunction  | Fun√ß√£o de pedigree de diabetes (risco gen√©tico familiar) | Num√©rico (decimal)   | ~0 a >2                     |
| Age                       | Idade da paciente                                     | Inteiro                | ‚â• 0                         |
| Outcome                   | Diagn√≥stico de diabetes                               | Categ√≥rico (bin√°rio)   | {0 = n√£o, 1 = sim}          |

</div>

### Atributos Principais

Para o projeto, foram selecionados os atributos principais do dataset: *Glucose* (glicose), *BMI* (√≠ndice de massa corporal), *Age* (idade), *DiabetesPedigreeFunction* (hist√≥rico familiar) e *Outcome* (resultado). Clinicamente, essas vari√°veis s√£o fundamentais para o diagn√≥stico do diabetes, e sua escolha tamb√©m considera o senso comum, j√° que, por exemplo, ao observar uma pessoa idosa e com sobrepeso, intuitivamente associamos a maior risco de problemas de sa√∫de.

<div align="center">

| Atributo | Motiva√ß√£o |
|----------|-----------|
| Glucose | Principal indicador de diabetes; valores altos est√£o fortemente associados √† doen√ßa. |
| BMI (√çndice de Massa Corporal) | Obesidade √© um fator de risco bem estabelecido para diabetes. |
| Age (Idade) | A probabilidade de diabetes aumenta com a idade. |
| DiabetesPedigreeFunction (Hist√≥rico familiar) | Mede predisposi√ß√£o gen√©tica; ajuda a capturar risco familiar. |
| Outcome (Resultado) | Representa o diagn√≥stico de diabetes (0 = n√£o, 1 = sim). |

</div>

### Pr√©-processamento de Dados

Para esta e as demais etapas, utilizamos Python com bibliotecas de Ci√™ncia de Dados (pandas, numpy, matplotlib, plotly e scikit-learn). O primeiro passo do pr√©-processamento dos dados foi realizar a redu√ß√£o dos atributos para considerar apenas aqueles que foram selecionados como principais para o projeto. Para a etapa de limpeza, foi verificado que os atributos *"Glucose (glicose)"* e *"BMI (√çndice de Massa Corporal)"* estavam preenchidos com valor zero em algumas linhas, o que n√£o faz sentido dentro do contexto cl√≠nico. Para isso, os valores 0 foram substitu√≠dos por *NaN*, permitindo posteriormente a remo√ß√£o de todas as linhas com valores ausentes do dataset. Com isso o dataset inicial com 768 linhas e 9 colunas passou a ter 752 linhas e 5 colunas.

```python
# substitui zeros inv√°lidos por NaN
df[["Glucose", "BMI"]] = df[["Glucose", "BMI"]].replace(0, np.nan)

# remove linhas com qualquer valor nulo nas vari√°veis selecionadas
df = df.dropna()
```

Ainda no pr√©-processamento, foi realizada uma etapa essencial: a transforma√ß√£o das vari√°veis num√©ricas, garantindo que todos os atributos estivessem padronizados na mesma escala. Isso porque, enquanto a idade pode variar at√© cerca de 80 anos, o DiabetesPedigreeFunction (hist√≥rico familiar) possui valores entre 0 e 2. Sem essa padroniza√ß√£o, os atributos n√£o seriam tratados de forma equilibrada no modelo. Nessa tarefa foi utilizada a classe ```StandardScaler``` (do scikit-learn) que serve para padronizar estat√≠sticamente as vari√°veis num√©ricas, ou seja, usa da f√≥rmula *Z-score* (ou escore-padr√£o) transformando os dados para que tenham m√©dia 0 e desvio padr√£o 1.

```python
# seleciona do DataFrame apenas as vari√°veis independentes que se deseja escalar
X = df[["Glucose", "BMI", "Age", "DiabetesPedigreeFunction"]]

X_scaled = scaler.fit_transform(X)
# fit: calcula para cada coluna a m√©dia (ùúá) e o desvio padr√£o (œÉ) a partir dos dados fornecidos
# transform: aplica a padroniza√ß√£o usando a f√≥rmula abaixo para cada valor
```

$$
z = \frac{x - \mu}{\sigma}
$$


## AN√ÅLISE DESCRITIVA

Na etapa de an√°lise descritiva, os dados s√£o explorados e resumidos para compreender suas caracter√≠sticas principais, identificar padr√µes e detectar poss√≠veis inconsist√™ncias. Essa fase inclui estat√≠sticas b√°sicas, distribui√ß√£o de valores, correla√ß√µes entre vari√°veis e visualiza√ß√µes gr√°ficas, servindo como base para decis√µes posteriores no projeto.

### Histograma

<div align="center">
  
| ![Histograma](/assets/histograma.png) |
|:--:|
| *Histograma de distribui√ß√£o sobreposta (stacked/overlapped histogram)* |

</div>

Esse gr√°fico mostra a distribui√ß√£o dos valores de glicose no conjunto de dados, separados de acordo com o diagn√≥stico de diabetes (Outcome).

- A cor vermelha representa pessoas sem diabetes (Outcome = 0), cuja maior concentra√ß√£o de valores est√° em torno de 90 a 110 mg/dL, regi√£o considerada mais pr√≥xima da normalidade.
- A cor azul representa pessoas com diabetes (Outcome = 1), que se concentram mais em valores acima de 120 mg/dL, indicando n√≠veis elevados de glicose.

Em resumo, o gr√°fico evidencia que valores mais altos de glicose est√£o fortemente associados ao diagn√≥stico positivo de diabetes, enquanto valores mais baixos predominam entre os indiv√≠duos sem a doen√ßa.



### Gr√°fico de Dispers√£o

<div align="center">
  
| ![Gr√°fico de Dispers√£o](/assets/scatterplot.png) |
|:--:|
| *Gr√°fico de Dispers√£o (scatter plot)* |

</div>

O que ele mostra:
- Eixo X (horizontal): valores de BMI (√≠ndice de massa corporal).
- Eixo Y (vertical): valores de Glicose.
- Cor dos pontos (cmap): vari√°vel categ√≥rica Outcome (0 = azul escuro, 1 = amarelo).

O gr√°fico mostra que pessoas sem diabetes (azul escuro) concentram-se em n√≠veis mais baixos de glicose, mesmo com varia√ß√µes de IMC, enquanto aquelas com diabetes (amarelo) apresentam valores mais elevados de glicose, independentemente do IMC, indicando que a glicose √© o principal fator diferenciador entre os grupos, embora o IMC tamb√©m contribua para o risco.



### Boxplot

<div align="center">
  
| ![Boxplot](/assets/boxplot.png) |
|:--:|
| *Boxplot* |

</div>

O que se observa:
- Para quem n√£o tem diabetes (Outcome = 0, vermelho), a mediana da idade est√° em torno de 27 anos, com a maioria concentrada entre aproximadamente 22 e 36 anos. H√° v√°rios outliers em idades mais altas.
- Para quem tem diabetes (Outcome = 1, azul), a mediana √© mais alta, por volta de 36 anos, e a faixa interquart√≠lica (25% a 75%) vai de cerca de 28 a 45 anos, mostrando que indiv√≠duos com diabetes tendem a ser mais velhos.
- A dispers√£o √© maior entre os diagnosticados com diabetes, mas fica evidente que a idade elevada est√° mais associada √† presen√ßa da doen√ßa.

Em resumo, o gr√°fico indica que a idade √© um fator relevante no risco de diabetes, com maior preval√™ncia em pessoas mais velhas.



## MODELAGEM

Nesta etapa de modelagem, ser√£o aplicados diferentes algoritmos de **Machine Learning** ao **Pima Indians Diabetes Dataset** com o intuito de gerar insights sobre os padr√µes presentes nos dados. Ser√£o utilizados dois m√©todos, um supervisionado (√Årvore de Decis√£o) e outro n√£o-supervisionado (K-Means).

### √Årvore de Decis√£o (Decision Tree)

A **√°rvore de decis√£o** √© um algoritmo de **aprendizado supervisionado** usado para classifica√ß√£o e regress√£o. Ela divide os dados em ramos com base nas vari√°veis mais relevantes, formando uma estrutura em forma de √°rvore. Cada divis√£o representa uma decis√£o, e as folhas finais indicam o resultado ou a previs√£o do modelo.

#### Configura√ß√£o da √Årvore de Decis√£o

Para o c√≥digo, foi utilizada a biblioteca ```Scikit-learn```, que fornece o m√≥dulo ```DecisionTreeClassifier```, respons√°vel pela constru√ß√£o, treinamento e avalia√ß√£o da √Årvore de Decis√£o. O modelo √© treinado com parte dos dados (treino) e avaliado em dados novos (teste). A fun√ß√£o ```train_test_split``` divide os dados de forma aleat√≥ria, mantendo a propor√ß√£o das classes com o par√¢metro ```stratify```, destinando 30% para teste e 70% para treino. O par√¢metro ```random_state=42``` garante que a divis√£o seja sempre a mesma, sendo 42 apenas um n√∫mero de refer√™ncia.

```python
# cria√ß√£o do modelo de √°rvore de decis√£o
clf = DecisionTreeClassifier(
    criterion="gini",
    max_depth=3,
    min_samples_leaf=20,
    random_state=42
)
```


- `criterion="gini"` ‚Üí a √°rvore usa o **√≠ndice de Gini** (ou, alternativamente, "entropy") para medir a impureza do n√≥.  
- `max_depth=3` ‚Üí limita a √°rvore a 3 n√≠veis, evitando complexidade excessiva.  
- `min_samples_leaf=20` ‚Üí cada folha precisa ter pelo menos 20 exemplos, prevenindo overfitting.

#### √çndice de Gini

O **√≠ndice de Gini** mede o qu√£o misturado est√° um n√≥; e √© calculado como:

$$
Gini = 1 - \sum_{i=1}^{n} p_i^2
$$

onde $$p_i$$ √© a propor√ß√£o de elementos da classe $$i$$ no n√≥. Quanto mais pr√≥ximo de 0, mais puro √© o n√≥; quanto mais pr√≥ximo de 1, mais misturado est√£o os dados.

#### Visualiza√ß√£o da √Årvore

<div align="center">
  
| ![√Årvore de Decis√£o (Decision Tree)](/assets/arvore-de-decisao.png) |
|:--:|
| *√Årvore de Decis√£o (Decision Tree)* |

</div>

- `feature <= valor` ‚Üí condi√ß√£o de decis√£o
- `gini` ‚Üí medida de impureza (0 = puro, 0.5 = misto)
- `samples` ‚Üí quantos exemplos chegaram at√© esse n√≥
- `value = [a, b]` ‚Üí n√∫mero de amostras das classes [N√£o Diab√©tico, Diab√©tico]
- `class = ...` ‚Üí decis√£o da √°rvore naquele n√≥

A √°rvore de decis√£o divide os dados em etapas para separar os grupos ‚ÄúDiab√©tico‚Äù e ‚ÄúN√£o Diab√©tico‚Äù. Ela come√ßa avaliando o n√≠vel de glicose, o fator mais determinante, e depois refina a decis√£o com idade, IMC e hist√≥rico familiar. Cada n√≥ mostra como o modelo reduz a incerteza at√© chegar √†s folhas, onde est√£o as previs√µes finais. Os tons alaranjados representam n√£o diab√©ticos e os tons azulados, diab√©ticos ‚Äî quanto mais escura a cor, mais certa √© a classifica√ß√£o. Al√©m disso, a idade se mostrou um divisor claro, pois nenhum indiv√≠duo com menos de "27,5" anos foi classificado como diab√©tico, deixando todo esse ramo da √°rvore composto apenas por n√≥s com resultados ‚ÄúN√£o Diab√©tico‚Äù.

| Padr√£o | Interpreta√ß√£o |
|------------|----------------|
| **Alta glicose** | √â o fator mais decisivo ‚Üí indica fortemente diabetes. |
| **Baixa glicose + baixo BMI + jovem** | Quase sempre n√£o diab√©tico. |
| **Hist√≥rico familiar alto (Pedigree alto)** | Aumenta bastante a chance de diabetes mesmo com glicose n√£o t√£o alta. |

### K-Means

O K-means √© um algoritmo de aprendizado n√£o supervisionado usado para agrupar dados semelhantes em K grupos (clusters). Ele funciona atribuindo cada ponto ao centro mais pr√≥ximo e ajustando esses centros iterativamente at√© que os grupos fiquem est√°veis. √â considerado o algoritmo de clusteriza√ß√£o mais simples e amplamente utilizado em **Machine Learning**, sendo ideal para descobrir padr√µes ou segmentos ocultos em conjuntos de dados sem r√≥tulos.

Para o c√≥digo, foi utilizada a biblioteca ```Scikit-learn```, que fornece o m√≥dulo ```KMeans```, respons√°vel pela realiza√ß√£o da clusteriza√ß√£o n√£o supervisionada. Diferente dos modelos de classifica√ß√£o, o K-Means n√£o utiliza r√≥tulos (classes) durante o treinamento, pois seu objetivo √© agrupar os dados com base em similaridades entre as vari√°veis. O modelo foi configurado para criar dois agrupamentos ```(n_clusters=2)```, e o par√¢metro ```random_state=42``` foi definido para assegurar a reprodutibilidade dos resultados. Ap√≥s o ajuste do modelo, cada amostra recebeu um r√≥tulo de cluster, permitindo a visualiza√ß√£o e an√°lise dos grupos formados.

#### Visualiza√ß√£o do Resultado

Para os agrupamentos, escolheu-se K = 2 porque o dataset naturalmente possui duas categorias (diab√©tico e n√£o diab√©tico), e o objetivo √© verificar se o K-Means consegue reproduzir essa separa√ß√£o de forma n√£o supervisionada. Abaixo, √© mostrado o gr√°fico de dispers√£o em fun√ß√£o de duas vari√°veis importantes: glicose e √≠ndice de massa corporal.

<div align="center">
  
| ![Gr√°fico de Dispers√£o do K-Means](/assets/k-means-scatterplot.png) |
|:--:|
| *K-Means Scatterplot com K = 2* |

</div>


O gr√°fico revela a forma√ß√£o de dois grupos principais:
- Cluster 1 (roxo): agrupa indiv√≠duos com valores mais baixos de glicose e BMI moderado, indicando um perfil mais pr√≥ximo de pacientes sem diabetes ou com menor risco metab√≥lico.
- Cluster 2 (amarelo): agrupa indiv√≠duos com n√≠veis de glicose mais elevados e, em geral, maior √≠ndice de massa corporal, o que pode estar associado a um maior risco de diabetes.

#### Valida√ß√£o

Para avaliar se o n√∫mero de clusters definido (K = 2) √© adequado, foi aplicada a t√©cnica de √çndice da Silhueta (Silhouette Score).

<div align="center">
  
| ![√çndice da Silhueta (Silhouette Score](/assets/silhouette-score-kmeans.png) |
|:--:|
| *√çndice da Silhueta (Silhouette Score)* |

</div>

Interpreta√ß√£o do gr√°fico:
- O eixo X (embaixo) √© o n√∫mero de clusters (K) testado, nesse caso indo de 2 at√© 8.
- O eixo Y esquerdo mostra o *Silhouette Score* que √© a linha azul.
- A linha azul representa o *Silhouette Score* para cada n√∫mero de clusters (K), o valor mostra o qu√£o bem os pontos est√£o agrupados, pois quanto maior o *Silhouette Score*, melhor o agrupamento.
- A linha verde ao fundo mostra o tempo que o algoritmo demorou para treinar *(fit time)*, ou seja, √© apenas um indicador de desempenho computacional e n√£o influencia na escolha do melhor K.

**Resultado:** o gr√°fico mostra que o maior valor de *Silhouette Score* ocorre em K = 2, com pontua√ß√£o 0.496. Depois desse ponto o *score* cai bastante, o que significa que os agrupamentos ficaram menos bem definidos √† medida que aumentamos o n√∫mero de clusters. Em resumo, o melhor K √© aquele onde o *Silhouette Score* √© m√°ximo, porque significa que os grupos est√£o mais bem separados e coesos internamente. Nesse caso K = 2 realmente √© o ideal.

---

## Informa√ß√£o Adicional

O c√≥digo completo pode ser conferido atrav√©s do Google Colab neste reposit√≥rio.


